{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "957e62de",
   "metadata": {},
   "source": [
    "# MODEL SELECTION TRAINING AND EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "86872be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "daa12a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('credit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9909f259",
   "metadata": {},
   "source": [
    "# FEATURE ENGINEEREING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "82fb879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of unwanted features\n",
    "unwanted_features = ['ID', 'Customer_ID', 'Name', 'Age', 'SSN', 'Type_of_Loan', 'Num_Credit_Inquiries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b817535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unwanted features\n",
    "df = df.drop(unwanted_features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a81f97c",
   "metadata": {},
   "source": [
    "# Handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1b9dee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of outliers in each numerical column\n",
    "numerical_cols = ['Month','Annual_Income','Monthly_Inhand_Salary','Num_Bank_Accounts','Num_Credit_Card','Interest_Rate',\n",
    "                  'Delay_from_due_date','Num_of_Delayed_Payment','Num_of_Loan','Changed_Credit_Limit',\n",
    "                  'Credit_Utilization_Ratio','Outstanding_Debt','Credit_History_Age',\n",
    "                  'Total_EMI_per_month', 'Amount_invested_monthly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "46ac805f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers in each column:\n",
      "Month: 0 outliers detected\n",
      "Annual_Income: 2000 outliers detected\n",
      "Monthly_Inhand_Salary: 2017 outliers detected\n",
      "Num_Bank_Accounts: 0 outliers detected\n",
      "Num_Credit_Card: 0 outliers detected\n",
      "Interest_Rate: 0 outliers detected\n",
      "Delay_from_due_date: 4002 outliers detected\n",
      "Num_of_Delayed_Payment: 0 outliers detected\n",
      "Num_of_Loan: 0 outliers detected\n",
      "Changed_Credit_Limit: 579 outliers detected\n",
      "Credit_Utilization_Ratio: 4 outliers detected\n",
      "Outstanding_Debt: 5272 outliers detected\n",
      "Credit_History_Age: 0 outliers detected\n",
      "Total_EMI_per_month: 5044 outliers detected\n",
      "Amount_invested_monthly: 4464 outliers detected\n"
     ]
    }
   ],
   "source": [
    "num_outliers = []\n",
    "for col in numerical_cols:\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_limit = q1 - 1.5 * iqr\n",
    "    upper_limit = q3 + 1.5 * iqr\n",
    "    outliers = df[(df[col] < lower_limit) | (df[col] > upper_limit)].shape[0]\n",
    "    num_outliers.append(outliers)\n",
    "\n",
    "print(\"Number of outliers in each column:\")\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    print(f\"{col}: {num_outliers[i]} outliers detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e64eb1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap outlier values\n",
    "# Calculate the upper and lower limits for outlier capping\n",
    "upper_limits = {}\n",
    "lower_limits = {}\n",
    "for col in numerical_cols:\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    upper_limits[col] = q3 + 1.5 * iqr\n",
    "    lower_limits[col] = q1 - 1.5 * iqr\n",
    "\n",
    "# Cap outlier values\n",
    "for col in numerical_cols:\n",
    "    df[col] = np.where(df[col] > upper_limits[col], upper_limits[col], df[col])\n",
    "    df[col] = np.where(df[col] < lower_limits[col], lower_limits[col], df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c1f4a08f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outliers after processing:\n",
      "Number of outliers in each column:\n",
      "Month: 0 outliers detected\n",
      "Annual_Income: 0 outliers detected\n",
      "Monthly_Inhand_Salary: 0 outliers detected\n",
      "Num_Bank_Accounts: 0 outliers detected\n",
      "Num_Credit_Card: 0 outliers detected\n",
      "Interest_Rate: 0 outliers detected\n",
      "Delay_from_due_date: 0 outliers detected\n",
      "Num_of_Delayed_Payment: 0 outliers detected\n",
      "Num_of_Loan: 0 outliers detected\n",
      "Changed_Credit_Limit: 0 outliers detected\n",
      "Credit_Utilization_Ratio: 0 outliers detected\n",
      "Outstanding_Debt: 0 outliers detected\n",
      "Credit_History_Age: 0 outliers detected\n",
      "Total_EMI_per_month: 0 outliers detected\n",
      "Amount_invested_monthly: 0 outliers detected\n"
     ]
    }
   ],
   "source": [
    "# Display the remaining outliers after processing\n",
    "print(\"\\nOutliers after processing:\")\n",
    "num_outliers = []\n",
    "for col in numerical_cols:\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_limit = q1 - 1.5 * iqr\n",
    "    upper_limit = q3 + 1.5 * iqr\n",
    "    outliers = df[(df[col] < lower_limit) | (df[col] > upper_limit)].shape[0]\n",
    "    num_outliers.append(outliers)\n",
    "\n",
    "print(\"Number of outliers in each column:\")\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    print(f\"{col}: {num_outliers[i]} outliers detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c16e2db",
   "metadata": {},
   "source": [
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dd740471",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['Occupation','Delay_from_due_date', 'Num_of_Delayed_Payment',\n",
    "                    'Credit_Mix','Payment_Behaviour','Payment_of_Min_Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3cb629b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75fb53",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "21937d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding:\n",
      "Good: 0\n",
      "Poor: 1\n",
      "Standard: 2\n"
     ]
    }
   ],
   "source": [
    "target_column = 'Credit_Score'\n",
    "label_encoder = LabelEncoder()\n",
    "df[target_column] = label_encoder.fit_transform(df[target_column])\n",
    "labels_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label Encoding:\")\n",
    "for label, code in labels_mapping.items():\n",
    "    print(f\"{label}: {code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495b3ace",
   "metadata": {},
   "source": [
    "# MODEL SELECTION AND TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8702a64f",
   "metadata": {},
   "source": [
    "# Train Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cc31a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into training, validation, and testing sets\n",
    "X = df.drop('Credit_Score', axis=1)\n",
    "y = df['Credit_Score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1844b2",
   "metadata": {},
   "source": [
    "# Random Forest Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "159a8887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classifier Accuracy: 80.81%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the RandomForestClassifier model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit a RandomForestClassifier model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for X_test\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Display accuracy\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"\\nRandom Forest Classifier Accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002f02e1",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90413be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Classifier Accuracy: 70.85%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize the Gradient Boosting Classifier model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit a Gradient Boosting Classifier model\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for X_test\n",
    "y_test_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Display accuracy\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"\\nGradient Boosting Classifier Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365c57cc",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "29302367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Classifier Accuracy: 72.84%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the Decision Tree Classifier to the training data\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for X_test\n",
    "y_test_pred = dt_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Display accuracy\n",
    "print(\"\\nDecision Tree Classifier Accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b89baa6",
   "metadata": {},
   "source": [
    "# Support Vector Classifier model (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1137ba65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Classifier Accuracy: 53.66%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize the Support Vector Classifier (SVC)\n",
    "svc_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "\n",
    "# Fit the SVC model to the training data\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for X_test\n",
    "y_test_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Display accuracy\n",
    "print(\"\\nSupport Vector Classifier Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07095976",
   "metadata": {},
   "source": [
    "# XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e3f0032a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Classifier Accuracy: 76.50%\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Convert data to DMatrix format, which is optimized for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Specify hyperparameters for XGBoost\n",
    "params = {\n",
    "    'objective': 'multi:softmax',  # Multi-class classification\n",
    "    'num_class': 3,  # Number of classes (replace with your actual number of classes)\n",
    "    'max_depth': 6,  # Maximum depth of trees\n",
    "    'eta': 0.3,  # Learning rate\n",
    "    'gamma': 0,  # Minimum loss reduction required to make a further partition\n",
    "    'subsample': 0.8,  # Subsample ratio of the training instances\n",
    "    'colsample_bytree': 0.8,  # Subsample ratio of columns when constructing each tree\n",
    "    'eval_metric': 'merror'  # Evaluation metric (merror for multi-class classification error)\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "num_rounds = 100  # Number of boosting rounds\n",
    "bst = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Display accuracy\n",
    "print(\"\\nXGBoost Classifier Accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ae76a8",
   "metadata": {},
   "source": [
    "# Naive Bayes classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "08f0c2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Classifier Accuracy: 60.19%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Train the Naive Bayes classifier on the training data\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for X_test\n",
    "y_test_pred = nb_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Display accuracy\n",
    "print(\"\\nNaive Bayes Classifier Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ba67bc",
   "metadata": {},
   "source": [
    "# MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07be8341",
   "metadata": {},
   "source": [
    "# Accuracy for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "41e8d74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy: 80.81%\n",
      "Gradient Boosting Classifier Accuracy: 70.85%\n",
      "Decision Tree Classifier Accuracy: 72.84%\n",
      "Support Vector Classifier Accuracy: 53.66%\n",
      "XGBoost Classifier Accuracy: 76.50%\n",
      "Naive Bayes Classifier Accuracy: 60.19%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate accuracy for each model\n",
    "accuracy_rf = accuracy_score(y_test, rf_model.predict(X_test))\n",
    "accuracy_gb = accuracy_score(y_test, gb_model.predict(X_test))\n",
    "accuracy_dt = accuracy_score(y_test, dt_model.predict(X_test))\n",
    "accuracy_svc = accuracy_score(y_test, svc_model.predict(X_test))\n",
    "accuracy_xgb = accuracy_score(y_test, bst.predict(dtest))\n",
    "accuracy_nb = accuracy_score(y_test, nb_model.predict(X_test))\n",
    "\n",
    "print(\"Random Forest Classifier Accuracy: {:.2f}%\".format(accuracy_rf * 100))\n",
    "print(\"Gradient Boosting Classifier Accuracy: {:.2f}%\".format(accuracy_gb * 100))\n",
    "print(\"Decision Tree Classifier Accuracy: {:.2f}%\".format(accuracy_dt * 100))\n",
    "print(\"Support Vector Classifier Accuracy: {:.2f}%\".format(accuracy_svc * 100))\n",
    "print(\"XGBoost Classifier Accuracy: {:.2f}%\".format(accuracy_xgb * 100))\n",
    "print(\"Naive Bayes Classifier Accuracy: {:.2f}%\".format(accuracy_nb * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f7398",
   "metadata": {},
   "source": [
    "# Confusion matrix for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0fc037a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Random Forest Classifier:\n",
      "[[2733    4  827]\n",
      " [ 122 4747  990]\n",
      " [ 761 1133 8683]]\n",
      "\n",
      "Confusion Matrix for Gradient Boosting Classifier:\n",
      "[[2423   21 1120]\n",
      " [ 539 3572 1748]\n",
      " [1297 1105 8175]]\n",
      "\n",
      "Confusion Matrix for Decision Tree Classifier:\n",
      "[[2320  172 1072]\n",
      " [ 151 4165 1543]\n",
      " [1037 1456 8084]]\n",
      "\n",
      "Confusion Matrix for Support Vector Classifier:\n",
      "[[   0   70 3494]\n",
      " [   0 1738 4121]\n",
      " [   0 1583 8994]]\n",
      "\n",
      "Confusion Matrix for Naive Bayes Classifier:\n",
      "[[2933   98  533]\n",
      " [1039 4199  621]\n",
      " [3146 2525 4906]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate confusion matrix for each model\n",
    "cm_rf = confusion_matrix(y_test, rf_model.predict(X_test))\n",
    "cm_gb = confusion_matrix(y_test, gb_model.predict(X_test))\n",
    "cm_dt = confusion_matrix(y_test, dt_model.predict(X_test))\n",
    "cm_svc = confusion_matrix(y_test, svc_model.predict(X_test))\n",
    "cm_nb = confusion_matrix(y_test, nb_model.predict(X_test))\n",
    "\n",
    "print(\"Confusion Matrix for Random Forest Classifier:\")\n",
    "print(cm_rf)\n",
    "print(\"\\nConfusion Matrix for Gradient Boosting Classifier:\")\n",
    "print(cm_gb)\n",
    "print(\"\\nConfusion Matrix for Decision Tree Classifier:\")\n",
    "print(cm_dt)\n",
    "print(\"\\nConfusion Matrix for Support Vector Classifier:\")\n",
    "print(cm_svc)\n",
    "print(\"\\nConfusion Matrix for Naive Bayes Classifier:\")\n",
    "print(cm_nb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b14f7ce",
   "metadata": {},
   "source": [
    "# Precision for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8576aeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for Random Forest Classifier: 0.81\n",
      "Precision for Gradient Boosting Classifier: 0.72\n",
      "Precision for Decision Tree Classifier: 0.73\n",
      "Precision for Support Vector Classifier: 0.44\n",
      "Precision for XGBoost Classifier: 0.77\n",
      "Precision for Naive Bayes Classifier: 0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Calculate precision for each model\n",
    "precision_rf = precision_score(y_test, rf_model.predict(X_test), average='weighted', zero_division=0)\n",
    "precision_gb = precision_score(y_test, gb_model.predict(X_test), average='weighted', zero_division=0)\n",
    "precision_dt = precision_score(y_test, dt_model.predict(X_test), average='weighted', zero_division=0)\n",
    "precision_svc = precision_score(y_test, svc_model.predict(X_test), average='weighted', zero_division=0)\n",
    "precision_xgb = precision_score(y_test, bst.predict(dtest), average='weighted', zero_division=0)\n",
    "precision_nb = precision_score(y_test, nb_model.predict(X_test), average='weighted', zero_division=0)\n",
    "\n",
    "print(\"Precision for Random Forest Classifier: {:.2f}\".format(precision_rf))\n",
    "print(\"Precision for Gradient Boosting Classifier: {:.2f}\".format(precision_gb))\n",
    "print(\"Precision for Decision Tree Classifier: {:.2f}\".format(precision_dt))\n",
    "print(\"Precision for Support Vector Classifier: {:.2f}\".format(precision_svc))\n",
    "print(\"Precision for XGBoost Classifier: {:.2f}\".format(precision_xgb))\n",
    "print(\"Precision for Naive Bayes Classifier: {:.2f}\".format(precision_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b11bcaf",
   "metadata": {},
   "source": [
    "# Recall for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a2e2a4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recall for Random Forest Classifier: 0.81\n",
      "Recall for Gradient Boosting Classifier: 0.71\n",
      "Recall for Decision Tree Classifier: 0.73\n",
      "Recall for Support Vector Classifier: 0.54\n",
      "Recall for XGBoost Classifier: 0.76\n",
      "Recall for Naive Bayes Classifier: 0.60\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Calculate recall for each model\n",
    "recall_rf = recall_score(y_test, rf_model.predict(X_test), average='weighted')\n",
    "recall_gb = recall_score(y_test, gb_model.predict(X_test), average='weighted')\n",
    "recall_dt = recall_score(y_test, dt_model.predict(X_test), average='weighted')\n",
    "recall_svc = recall_score(y_test, svc_model.predict(X_test), average='weighted')\n",
    "recall_xgb = recall_score(y_test, bst.predict(dtest), average='weighted')\n",
    "recall_nb = recall_score(y_test, nb_model.predict(X_test), average='weighted')\n",
    "\n",
    "print(\"\\nRecall for Random Forest Classifier: {:.2f}\".format(recall_rf))\n",
    "print(\"Recall for Gradient Boosting Classifier: {:.2f}\".format(recall_gb))\n",
    "print(\"Recall for Decision Tree Classifier: {:.2f}\".format(recall_dt))\n",
    "print(\"Recall for Support Vector Classifier: {:.2f}\".format(recall_svc))\n",
    "print(\"Recall for XGBoost Classifier: {:.2f}\".format(recall_xgb))\n",
    "print(\"Recall for Naive Bayes Classifier: {:.2f}\".format(recall_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cd7986",
   "metadata": {},
   "source": [
    "# F1-score for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "090098f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1-score for Random Forest Classifier: 0.81\n",
      "F1-score for Gradient Boosting Classifier: 0.71\n",
      "F1-score for Decision Tree Classifier: 0.73\n",
      "F1-score for Support Vector Classifier: 0.46\n",
      "F1-score for XGBoost Classifier: 0.76\n",
      "F1-score for Naive Bayes Classifier: 0.60\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate F1-score for each model\n",
    "f1_rf = f1_score(y_test, rf_model.predict(X_test), average='weighted')\n",
    "f1_gb = f1_score(y_test, gb_model.predict(X_test), average='weighted')\n",
    "f1_dt = f1_score(y_test, dt_model.predict(X_test), average='weighted')\n",
    "f1_svc = f1_score(y_test, svc_model.predict(X_test), average='weighted')\n",
    "f1_xgb = f1_score(y_test, bst.predict(dtest), average='weighted')\n",
    "f1_nb = f1_score(y_test, nb_model.predict(X_test), average='weighted')\n",
    "\n",
    "print(\"\\nF1-score for Random Forest Classifier: {:.2f}\".format(f1_rf))\n",
    "print(\"F1-score for Gradient Boosting Classifier: {:.2f}\".format(f1_gb))\n",
    "print(\"F1-score for Decision Tree Classifier: {:.2f}\".format(f1_dt))\n",
    "print(\"F1-score for Support Vector Classifier: {:.2f}\".format(f1_svc))\n",
    "print(\"F1-score for XGBoost Classifier: {:.2f}\".format(f1_xgb))\n",
    "print(\"F1-score for Naive Bayes Classifier: {:.2f}\".format(f1_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008fd85a",
   "metadata": {},
   "source": [
    "# After close evaluation 'Random Forest Classifier model' turns out to be the better model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
